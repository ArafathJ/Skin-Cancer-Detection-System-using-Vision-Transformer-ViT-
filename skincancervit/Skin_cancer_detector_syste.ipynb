{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Add your Kaggle API key in the choose file section after running the below cell which is available on your kaggle setting inorder to connect the colab.**"
      ],
      "metadata": {
        "id": "kK78gFNZ98yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own Kaggle API key from https://www.kaggle.com/account\n",
        "# from google.colab import files\n",
        "# files.upload()  # Upload kaggle.json\n"
      ],
      "metadata": {
        "id": "PPslpDvG9rzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make .kaggle/ directory on this session and the change access of the directory through chmod 600 and then join the .kaggle/ dir as like this .kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0UV-xN4BB48j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to store the dataset in some persistent storage area you can use Gdrive. So mount the drive"
      ],
      "metadata": {
        "id": "7YHBq1LA-dft"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "061QDw563n66"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Note Use can use (!cp source destination) command to load the dataset to the drive location\n",
        "\n",
        "# Define the path to the dataset directory in Google Drive storing the dataset in the drive\n",
        "# IMPORTANT: Users should update this path to where they have stored the HAM10000 dataset\n",
        "image_path = \"/content/drive/MyDrive/Colab_Notebooks/ham10000\" # <--- Update this path\n",
        "\n",
        "# Verify that the directory exists and list some files\n",
        "if os.path.exists(image_path):\n",
        "    print(f\"Dataset directory found at: {image_path}\")\n",
        "    print(\"First 5 files in the directory:\", os.listdir(image_path)[:5])\n",
        "else:\n",
        "    print(f\"Error: Dataset directory not found at {image_path}\")\n",
        "    print(\"Please update the 'image_path' variable to the correct location of the HAM10000 dataset in your Google Drive.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Below it is a sample cell to check whether I can access the image file"
      ],
      "metadata": {
        "id": "DU5JkzpUACIK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0r74s-14ESsK"
      },
      "outputs": [],
      "source": [
        "import PIL.Image as Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image_path = '/content/drive/MyDrive/Colab_Notebooks/ham10000/HAM10000_images_part_1/ISIC_0024306.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title('Example Image')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping all the target values into numbers for model training"
      ],
      "metadata": {
        "id": "YIci4smSAVoj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PEJ29sX-5aM"
      },
      "outputs": [],
      "source": [
        "label2id = {\n",
        "    \"akiec\": 0,\n",
        "    \"bcc\": 1,\n",
        "    \"bkl\": 2,\n",
        "    \"df\": 3,\n",
        "    \"mel\": 4,\n",
        "    \"nv\": 5,\n",
        "    \"vasc\": 6\n",
        "}\n",
        "\n",
        "id2label = {v:k for k, v in label2id.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NZAD6uBG9i4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path to the metadata CSV file in Google Drive\n",
        "# IMPORTANT: Users should update this path to where they have stored the HAM10000_metadata.csv file\n",
        "metadata_path = \"/content/drive/MyDrive/Colab_Notebooks/ham10000/HAM10000_metadata.csv\" # <--- Update this path\n",
        "\n",
        "# Define the base path to the image directory in Google Drive\n",
        "# Ensure this matches the path defined in the previous cell\n",
        "image_base_path = \"/content/drive/MyDrive/Colab_Notebooks/ham10000\" # <--- Ensure this matches the path in cell 061QDw563n66\n",
        "\n",
        "df = pd.read_csv(metadata_path)\n",
        "\n",
        "# Construct the full image path using the base path in image_id\n",
        "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(image_base_path, f\"HAM10000_images_part_1/{x}.jpg\")) # Adjust subfolder if necessary\n",
        "\n",
        "# Map the string labels in dx field to number labels in new 'label' field in df\n",
        "df['label'] = df['dx'].map(label2id)\n",
        "\n",
        "\n",
        "# Filter out rows where the image file does not exist\n",
        "df = df[df['image_path'].apply(lambda x: os.path.exists(x))]\n",
        "\n",
        "train_df , test_df = train_test_split(df, test_size=0.2, stratify = df['label'], random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjZzMMHD_nhq"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "# Define the name of the pre-trained model from Hugging Face\n",
        "model_name = 'google/vit-base-patch16-224-in21k'\n",
        "\n",
        "# Load the image processor associated with the pre-trained model\n",
        "# This processor will handle image resizing, normalization, etc.\n",
        "image_processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "\n",
        "# Load the pre-trained model for image classification\n",
        "image_model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels = len(label2id),\n",
        "    label2id = label2id,\n",
        "    id2label = id2label\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXRcTxHLEwRO"
      },
      "outputs": [],
      "source": [
        "#building a custom dataset from dataset class\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "# Define a custom PyTorch Dataset for loading skin cancer images and labels\n",
        "class SkinCancerDataset(Dataset):\n",
        "\n",
        "  # Constructor: initializes the dataset with a DataFrame and an image processor\n",
        "  def __init__(self, df, image_processor):\n",
        "    self.df = df.reset_index(drop=True)\n",
        "    self.image_processor = image_processor\n",
        "\n",
        "  # Returns the total number of samples in the dataset\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  # Returns a single sample (image and label) at the given index\n",
        "  def __getitem__(self, idx):\n",
        "    # Open the image file, convert to RGB format\n",
        "    image = Image.open(self.df.loc[idx, 'image_path']).convert(\"RGB\")\n",
        "    # Get the corresponding label (integer id)\n",
        "    label = self.df.loc[idx, 'label']\n",
        "\n",
        "    # Preprocess the image using the image processor, return as PyTorch tensors\n",
        "    inputs = self.image_processor(images=image, return_tensors=\"pt\")\n",
        "    # Remove the batch dimension added by the image processor\n",
        "    inputs = {k:v.squeeze(0) for k, v in inputs.items()}\n",
        "    # Add the label as a PyTorch tensor to the inputs dictionary\n",
        "    inputs[\"labels\"] = torch.tensor(label)\n",
        "\n",
        "    # Return the dictionary containing processed image inputs and the label\n",
        "    return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Y2BVDuN5OL"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create instances of the custom SkinCancerDataset for the training and test dataframes\n",
        "\n",
        "new_traindf = SkinCancerDataset(train_df, image_processor)\n",
        "new_testdf = SkinCancerDataset(test_df, image_processor)\n",
        "\n",
        "# These objects will handle loading and preprocessing images during training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "import numpy as np # Import numpy for the compute_metrics function\n",
        "from sklearn.metrics import accuracy_score # Import accuracy_score as well\n",
        "\n",
        "# Define the compute_metrics function\n",
        "# This function is used to calculate metrics during evaluation\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Computes accuracy on a batch of predictions.\"\"\"\n",
        "    predictions = eval_pred.predictions\n",
        "    labels = eval_pred.label_ids\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
        "\n",
        "# Define the training arguments\n",
        "# These arguments configure the training process, such as batch size, epochs, evaluation strategy, etc.\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./result',\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    logging_dir='./logs',\n",
        "    report_to=\"wandb\",\n",
        "    fp16=True\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "# The Trainer handles the training and evaluation loop\n",
        "trainer = Trainer(\n",
        "    model=image_model,\n",
        "    args=training_args,\n",
        "    train_dataset=new_traindf,\n",
        "    eval_dataset=new_testdf,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ],
      "metadata": {
        "id": "XJRT25SKl9JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWDiovohTuIR"
      },
      "outputs": [],
      "source": [
        "trainer.train() # Finally Train the model this will take some time so enable a gpu for faster performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79621cab"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source and destination paths\n",
        "source_dir = './result'  # The output directory specified in TrainingArguments\n",
        "destination_dir = '/content/drive/MyDrive/Colab_Notebooks/ham10000/trained_model' # Replace with your desired path in Google Drive\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "# Copy the contents of the source directory to the destination directory\n",
        "shutil.copytree(source_dir, destination_dir, dirs_exist_ok=True)\n",
        "\n",
        "print(f\"Model saved to: {destination_dir}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce4b034d"
      },
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "\n",
        "# Define the path to the saved model in your Google Drive\n",
        "model_path = '/content/drive/MyDrive/Colab_Notebooks/ham10000/trained_model/checkpoint-1500'\n",
        "\n",
        "# Load the image processor\n",
        "loaded_image_processor = AutoImageProcessor.from_pretrained('/content/drive/MyDrive/Colab_Notebooks/ham10000/trained_model/checkpoint-1500/config.json')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = AutoModelForImageClassification.from_pretrained(model_path)\n",
        "\n",
        "print(\"Model and image processor loaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67ed73ff"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import random\n",
        "from PIL import Image # Import Image\n",
        "\n",
        "# Select a random image path from the test dataset\n",
        "new_image_path = random.choice(test_df['image_path'].tolist())\n",
        "\n",
        "# Open the selected image and convert it to RGB format\n",
        "image = Image.open(new_image_path).convert(\"RGB\")\n",
        "\n",
        "# Find the information for this image in the original dataframe to get the actual label\n",
        "image_info = df[df['image_path'] == new_image_path]\n",
        "\n",
        "# Check if the image information was found and print the actual label\n",
        "if not image_info.empty:\n",
        "    actual_label_id = image_info.iloc[0]['label']\n",
        "    actual_label = id2label[actual_label_id]\n",
        "    print(f\"Image path: {new_image_path}\")\n",
        "    print(f\"The actual skin cancer type for the image is: {actual_label}\")\n",
        "else:\n",
        "    actual_label = \"N/A (Image not found in original data)\"\n",
        "    print(f\"Image path: {new_image_path}\")\n",
        "    print(f\"The actual skin cancer type for the image is: {actual_label}\")\n",
        "\n",
        "# Preprocess the image using the loaded image processor\n",
        "# This prepares the image for the model input\n",
        "inputs = loaded_image_processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "# Determine the device (GPU or CPU) to run the inference on\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "loaded_model.to(device) # Move the loaded model to the selected device\n",
        "\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()} # Move the input tensors to the selected device\n",
        "\n",
        "# Perform inference using the loaded model\n",
        "# torch.no_grad() is used to disable gradient calculation during inference to save memory and speed up computation\n",
        "with torch.no_grad():\n",
        "    outputs = loaded_model(**inputs)\n",
        "\n",
        "# Get the logits (raw output scores) from the model's output\n",
        "logits = outputs.logits\n",
        "\n",
        "# Get the predicted class ID by finding the index of the maximum logit score\n",
        "predicted_class_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "# Calculate the probabilities for each class using softmax\n",
        "probabilities = F.softmax(logits, dim=1)[0]\n",
        "\n",
        "# Get the probability for the predicted class\n",
        "predicted_probability = probabilities[predicted_class_id].item()\n",
        "\n",
        "# Map the predicted class ID back to its string label\n",
        "predicted_label = id2label[predicted_class_id]\n",
        "\n",
        "# Print the predicted skin cancer type and its confidence score\n",
        "print(f\"The predicted skin cancer type from the model is: {predicted_label}\")\n",
        "print(f\"Confidence score (probability): {predicted_probability:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the last cell multiple times for checking the prediction score / confidence score... Each time a new image will be picked from the validation dataset and see if  the original label from the dataset corresponds to my trained model**"
      ],
      "metadata": {
        "id": "ah6UiFos1vRM"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}